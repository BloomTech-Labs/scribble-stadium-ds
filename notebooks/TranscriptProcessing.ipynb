{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from os import listdir, chdir\n",
    "from re import compile as rcompile\n",
    "from path import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transcript(file_name):\n",
    "    file_names = glob(f'{file_name}*')\n",
    "    ret = ''\n",
    "    for fname in file_names:\n",
    "        with open(fname) as fd:\n",
    "            ret += fd.read()+'\\n\\n'\n",
    "    return ret\n",
    "\n",
    "reference_transcripts_dir = '../data/transcripts'\n",
    "google_transcripts_dir = '../data/google_transcripts'\n",
    "\n",
    "reference_transcripts_files = listdir(reference_transcripts_dir)\n",
    "google_transcripts_files = listdir(google_transcripts_dir)\n",
    "reference_transcripts_files.sort()\n",
    "google_transcripts_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '3101.txt', '3102.txt', '3103.txt', '3104.txt', '3105.txt', '3106.txt', '3107.txt', '3108.txt', '3109.txt', '3110.txt', '3111.txt', '3112.txt', '3113.txt', '3114.txt', '3115.txt', '3116.txt', '3117.txt', '3118.txt', '3119.txt', '3120.txt', '3121.txt', '3122.txt', '3123.txt', '3124.txt', '3125.txt', '3126.txt', '3127.txt', '3128.txt', '3129.txt', '3130.txt', '3131.txt', '3132.txt', '3201.txt', '3202.txt', '3203.txt', '3204.txt', '3205.txt', '3206.txt', '3207.txt', '3208.txt', '3209.txt', '3210.txt', '3211.txt', '3212.txt', '3213 (missing page 2).txt', '3214.txt', '3215 (missing page 2).txt', '3216.txt', '3217.txt', '3218.txt', '3219.txt', '3220.txt', '3221.txt', '3222.txt', '3223.txt', '3224.txt', '3225.txt', '3226.txt', '3227.txt', '3228.txt', '3229.txt', '3230.txt', '3231.txt', '3232.txt', '3234.txt', '3235.txt', '3236.txt', '3237.txt', '3238.txt', '3239.txt', '3240.txt', '3241.txt', '3243.txt', '3244.txt', '3245.txt', '3246.txt', '3247.txt', '3248.txt', '5101.txt', '5102.txt', '5103.txt', '5104.txt', '5105.txt', '5106.txt', '5107.txt', '5108.txt', '5109.txt', '5110.txt', '5111.txt', '5112.txt', '5113.txt', '5114.txt', '5115.txt', '5116.txt', '5117.txt', '5118.txt', '5119.txt', '5120.txt', '5121.txt', '5122.txt', '5123.txt', '5124.txt', '5125.txt', '5126.txt', '5129.txt', '5130.txt', '5131.txt', '5132.txt', '5202.txt', '5203.txt', '5204.txt', '5205.txt', '5206.txt', '5207.txt', '5208.txt', '5209.txt', '5210.txt', '5213.txt', '5214.txt', '5215.txt', '5216.txt', '5217.txt', '5218.txt', '5219.txt', '5220.txt', '5221.txt', '5222.txt', '5223.txt', '5224.txt', '5225.txt', '5227.txt', '5228.txt', '5229.txt', '5230.txt', '5232.txt', '5233.txt', '5234.txt', '5235.txt', '5236.txt', '5237.txt', '5238.txt', '5239.txt', '5240.txt', '5241.txt', '5242.txt', '5243.txt', '5244.txt', '5245.txt', '5246.txt', '5247.txt', '5248.txt', '5249.txt', '5250.txt', '5251.txt', '5252.txt', '5253.txt', '5254.txt', '5255.txt', '5256.txt', '5257.txt', '5258.txt', '5259.txt', '5260.txt', '5261.txt', '5262.txt', '5263.txt', '5264.txt']\n",
      "['.ipynb_checkpoints', '3101', '3102-1', '3102-2', '3103-1', '3103-2', '3104-1', '3104-2', '3105', '3106', '3107-1', '3107-2', '3108', '3109-1', '3109-2', '3110 ', '3111', '3112', '3113-1', '3113-2', '3114-1', '3114-2', '3115-1', '3115-2', '3116-1', '3116-2', '3117 ', '3118', '3119', '3120', '3121', '3122', '3123-1', '3123-2', '3124-1', '3124-2', '3125', '3126 ', '3127', '3128', '3129', '3130 ', '3131', '3132-1', '3132-2', '3201-1', '3201-2', '3202', '3203', '3204-1', '3204-2', '3205-1', '3205-2', '3206-1', '3206-2', '3207', '3208-1', '3208-2', '3209-1', '3209-2', '3210-1', '3210-2', '3210-3', '3211-1', '3211-2', '3212-1', '3212-2', '3212-3', '3213-1', '3213-2', '3213-3', '3214-1', '3215-1', '3215-2', '3215-3', '3216-1', '3216-2', '3216-3', '3216-4', '3217-1', '3217-2', '3218-1', '3218-2', '3219-1', '3219-2', '3220-1', '3220-2', '3220-3', '3221-1', '3221-2', '3222-1', '3222-2', '3223-1', '3223-2', '3224-1', '3224-2', '3225-1', '3225-2', '3226-1', '3226-2', '3227-1', '3227-2', '3228', '3229-1', '3229-2', '3230-1', '3230-2', '3231-1', '3231-2', '3232-1', '3232-2', '3234-1', '3234-2', '3235-1', '3235-2', '3236', '3237', '3238', '3239-1', '3239-2', '3240-2', '3241-1', '3241-2', '3243-1', '3243-2', '3244-1', '3244-2', '3245-1', '3245-2', '3246-1', '3246-2', '3247-1', '3247-2', '3248', '5101', '5102-1', '5102-2', '5103', '5104', '5105-1', '5105-2', '5106-1', '5106-2', '5107-1', '5107-2', '5108', '5109', '5110-1', '5110-2', '5111-1', '5111-2', '5112', '5113', '5114-1', '5114-2', '5115', '5116', '5117-1', '5117-2', '5118-1', '5118-2', '5119-1', '5119-2', '5120', '5121', '5122', '5123', '5124-1', '5124-2', '5124-3', '5125-1', '5125-2', '5126', '5129-1', '5129-2', '5129-3', '5130-1', '5130-2', '5130-3', '5130-4', '5131-1', '5131-2', '5131-3', '5132-1', '5132-2', '5202-1', '5202-2', '5203-1', '5203-2', '5204-1', '5204-2', '5205-1', '5205-2', '5205-3', '5206-1', '5206-2', '5207', '5208-1', '5208-2', '5209-1', '5209-2', '5210', '5213-1', '5213-2', '5213-3', '5214-1', '5214-2', '5215-1', '5215-2', '5215-3', '5216-1', '5216-2', '5217-1', '5217-2', '5218-1', '5218-2', '5219-1', '5219-2', '5220-1', '5220-2', '5220-3', '5221-1', '5221-2', '5222-1', '5222-2', '5223-1', '5223-2', '5223-3', '5224-1', '5224-2', '5225-1', '5225-2', '5227-1', '5227-2', '5228-1', '5228-2', '5229-1', '5229-2', '5230', '5232-1', '5232-2', '5233', '5234-1', '5234-2', '5234-3', '5234-4', '5235-1', '5235-2', '5235-3', '5236-1', '5236-2', '5236-3', '5237-1', '5237-2', '5237-3', '5238-1', '5238-2', '5239-1', '5239-2', '5240-1', '5240-2', '5241-1', '5241-2', '5242-1', '5242-2', '5243-1', '5243-2', '5244-1', '5244-2', '5245-1', '5245-2', '5245-3', '5245-4', '5245-5', '5245-6', '5245-7', '5246-1', '5246-2', '5247-1', '5247-2', '5248-1', '5248-2', '5249-1', '5249-2', '5250-1', '5250-2', '5250-3', '5251-1', '5251-2', '5252-1', '5252-2', '5253-1', '5253-2', '5254-1', '5254-2', '5254-3', '5254-4', '5255-1', '5255-2', '5256', '5257-1', '5257-2', '5258-1', '5258-2', '5259-1', '5259-2', '5260', '5261-1', '5261-2', '5262-1', '5262-2', '5263-1', '5263-2', '5264-1', '5264-2']\n"
     ]
    }
   ],
   "source": [
    "print(reference_transcripts_files)\n",
    "print(google_transcripts_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3101', '3102', '3103', '3104', '3105', '3106', '3107', '3108', '3109', '3110', '3111', '3112', '3113', '3114', '3115', '3116', '3117', '3118', '3119', '3120', '3121', '3122', '3123', '3124', '3125', '3126', '3127', '3128', '3129', '3130', '3131', '3132', '3201', '3202', '3203', '3204', '3205', '3206', '3207', '3208', '3209', '3210', '3211', '3212', '3214', '3216', '3217', '3218', '3219', '3220', '3221', '3222', '3223', '3224', '3225', '3226', '3227', '3228', '3229', '3230', '3231', '3232', '3234', '3235', '3236', '3237', '3238', '3239', '3240', '3241', '3243', '3244', '3245', '3246', '3247', '3248', '5101', '5102', '5103', '5104', '5105', '5106', '5107', '5108', '5109', '5110', '5111', '5112', '5113', '5114', '5115', '5116', '5117', '5118', '5119', '5120', '5121', '5122', '5123', '5124', '5125', '5126', '5129', '5130', '5131', '5132', '5202', '5203', '5204', '5205', '5206', '5207', '5208', '5209', '5210', '5213', '5214', '5215', '5216', '5217', '5218', '5219', '5220', '5221', '5222', '5223', '5224', '5225', '5227', '5228', '5229', '5230', '5232', '5233', '5234', '5235', '5236', '5237', '5238', '5239', '5240', '5241', '5242', '5243', '5244', '5245', '5246', '5247', '5248', '5249', '5250', '5251', '5252', '5253', '5254', '5255', '5256', '5257', '5258', '5259', '5260', '5261', '5262', '5263', '5264']\n"
     ]
    }
   ],
   "source": [
    "#Some of the reference transcripts have missing information and those files have\n",
    "#filename with '(missing page <number>)' substrings - filter these files out for\n",
    "#now.\n",
    "rex = rcompile('[0-9]+.txt')\n",
    "reference_transcripts_file_roots = [x.split('.')[0] for x in reference_transcripts_files if rex.match(x) is not None]\n",
    "print(reference_transcripts_file_roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 \n",
      " Once apon a time there was a girl named Mary. On a warm \n",
      "sunny day Mary was walking through the woods near hear nouse \n",
      "to look for some critters to take pictures of. She loved animals \n",
      "and nature all her life even though she was only nine years old \n",
      "She thinks that she is going to die soon. She does go to school \n",
      "but she isn't that smart. For example Mary recycled a pie \n",
      "even though the pie was not even bitten. Another thing she did \n",
      "was leave her muffin in the woods while she was traveling with  \n",
      "her family to Andrea's house which is one of Mary's friends at \n",
      "school and Mary's muffin was eaten by a bear that sniffed it :q!\n",
      ":\n",
      "from far away. Yes. Mary could be a little weird but that is \n",
      "just how she is. Back to the real story now. Mary found a \n",
      "fox, took a picture she also found a rabbit took a picture \n",
      "she found a squirrel and took a picture before it ran away. \n",
      "But sooner or later she saw two eyes peeking through a bush \n",
      "on the side of the path she was walking on. Then the \n",
      "creature slowly came out of the bush. It was a bear. The bear \n",
      "growled at Mary. Mary was terrifyed. She started running and \n",
      "running but she could still see the bear growling behind her. This \n",
      "was the end of Mary. Mary was approaching her house she \n",
      "could see it now. She was safe in her house. She was now \n",
      "really scared. She could possibly be eaten but she made it to \n",
      "the door opened it and slammed it shut before the bear could \n",
      "get in. She ran or sprinted rather up to her room. \"I'm alive!!\" \n",
      "She cried. I just can't belive it I'm alive!!\" Mary was so \n",
      "relifed she told her mom and dad and her brother. And that \n",
      "night Mary was kissed goodnight and tucked into bed. And that \n",
      "is the only brave time of her life.\n",
      "\n",
      " \n",
      " The secret fifth grade\n",
      "I am Amelia I am starting fifth grade.\n",
      "I have a little siter named Emma, Emma is\n",
      "goining into kindergarden, with her triplets\n",
      "Ava and Isabella, but I don't care\n",
      "about them. When I was a 3rd grader\n",
      "we learned how to invent. This year I \n",
      "will try to make an invention that \n",
      "a robot will go to school for me. Got to \n",
      "go to sleep. zzzzzz. I wake up \n",
      "get changed, brush teeth, and do hair. \n",
      "I have long curly brown hair. I used \n",
      "to wear glasses and braces, and once \n",
      "broke my leg. I am 10, I will turn 11 \n",
      "in November. The school is called Los Angeles \n",
      "elementry school. I live in Nevada and \n",
      "will drive there. It is probabaly an hour. \n",
      "When I walked in Mrs. Begula said \n",
      "Hello! Mrs. Klapeia, my last name. I said \n",
      "hi. I have to share a desk with Brittney. \n",
      "My schedule: Math Writting, reading, vocab, spelling, \n",
      "typing, and social studies. It had said NO \n",
      "Lunch In Fifth grade! When I was \n",
      "in second grade Kayla calle me a division \n",
      "Decimal. I did not like it. We had to make \n",
      "division problems and they were all with \n",
      "decimals. Class dismissed said Mrs. Begula. \n",
      "Now I was not a witch, vampire, or godess, but I \n",
      "made a sock from Emma and made it \n",
      "do my homework. When it was time to go \n",
      "I didn't I made a blue robot the whole \n",
      "night. Blue is my favorite color, but it only \n",
      "had a blue shirt because my teacher would \n",
      "notice it is not me. I sent it out with \n",
      "my mom. I went on my phone, until Ava \n",
      "came in my room. She said loudly \n",
      "Why are you not at school! Good thing \n",
      "she did not notice. I had to say something \n",
      "um I am sick. Cof cof cof. Oh I see \n",
      "let me tell Isabella. Isabella I heard she \n",
      "said. No said Ava. Should I tell Mom if \n",
      "she's really sick. Um no said Isabella \n",
      "play with me. Isabella already new \n",
      "about it. It the robot came back. \n",
      "It worked yay, and that is my year \n",
      "of fifth grade, When the home work \n",
      "is home. You are are doing my homework!\n",
      "\n",
      "\n",
      "\n",
      "165 \n",
      " - 3101 Once apon a time there was a girl named Mary. On a warm Sunny day Mary was wealking through the woods near her house to look for some critters to take pictures of She loved animals and nature all her life even though she was only nine years old She thinks that she is going to die soon, she does go to school but she isn't that smart, for example Mary recycled a pie even though the pie was not even bitten. Another thing she did Was leave her muffin in the woods while she was traveling with her family to Andrea's house which is one of Mary's friends at school and Mary's muffin was eaten by a bear that sniffer it from far away. Yes, Mary could be a little Weird but that is tust how she is. Back to the real story nowo Mary found a fox, took a picture she also found a rabbit took a picture She found a squirrel and took a picture before it ran away, But sooner or later she saw the eyes peeking through a bush on the site of the path she was walking on. Then the creature slowly came out of the bush. It was a bear. The bear grabled at Mary, Mary was terrifyed, she started running and running but she could still see the bear growling behind her. This was the and of Mary, Mary was approaching her have she could see it now, she was sate in her house, She was now really scared. She could possibly be eaten but she made it to the door opened it and slammed it shut before the bear could get in, she ran or sprinted rather up to her room. \"I'm alive!!! she cried, I just can't belive it I'm alive!!! Mary was so relifed she told her mom and dad and her brother. And that night Mary was kissed good night and thaked into bed. And that is the only brave time of her life. \n",
      "\n",
      " \n",
      " The secret fifth grade - 3102 E am Abeilia I am starting fifth grade I have alittle ster named Emma, Emma is goining into kindergarden, wi theer triplets Aver and Isabella, but I don't care about them when I was a 3rd grader leamed bow to invento This year I will try to make an invention that arobot Wil go to school forme. Got to go to deep. Ezzzzz. I wake up get changed, brush teeth, and do hair have long curly brown hair. I used to wear glasses and braces, and once broke my leg. I am 10, I will turn il in November The school is called Los Angeles elementry school, I live in Nevada and will drive there. It is probably an hour When I walked in Mrs. Begula said Hello Mrsklape, my last name I said his I have to share a desk with Brittney typing, and social stadies. It had said No My Schedule Math wetting reading, Vocabiespelling. Lunch In, Fifth grade When I was in second grade Kayla called me a division Decimal. I did not like it. we had to make division problems and they were all with iecimals Class dismissed said Mrs. Begular Now I was not a witch wampice, or godess, but I made asock from Emana and made it do my homework. When it was time to go \n",
      "\n",
      "3102 I didn't I made a blue robet the whole night Blue is my favorite color but it only had a blue shirt because my teacher would hotice it is not me, I sent it out with Came in my room She said bond mayoneem. Prventions are phone on this Ava Why are you not at school. Good thing She did not notice. I had to say something un I am sick of (of cof, oht see let me tell Isabella Isabella I heard she said. Mo suid Ava. Should I tell mom it she's really sick um no raid Isabella play with me. Isabella already new about it. It the robot came back It worker yay, and that is my year of fifth grade. When the home work is home you are doing my home werkt \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with Path(reference_transcripts_dir):\n",
    "    reference_transcripts = [read_transcript(f'{x}.txt') for x in reference_transcripts_file_roots]\n",
    "\n",
    "print(len(reference_transcripts),'\\n', reference_transcripts[0],'\\n', reference_transcripts[1])\n",
    "\n",
    "with Path(google_transcripts_dir):\n",
    "    google_transcripts = [read_transcript(x) for x in reference_transcripts_file_roots]\n",
    "    \n",
    "print(len(google_transcripts),'\\n', google_transcripts[0],'\\n', google_transcripts[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 21876)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 meet</th>\n",
       "      <th>00 morning</th>\n",
       "      <th>00 said</th>\n",
       "      <th>00 star</th>\n",
       "      <th>00 telling</th>\n",
       "      <th>00 time</th>\n",
       "      <th>000</th>\n",
       "      <th>000 000</th>\n",
       "      <th>000 5203</th>\n",
       "      <th>...</th>\n",
       "      <th>zoe told</th>\n",
       "      <th>zoe wasn</th>\n",
       "      <th>zoe worms</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zoomed planted</th>\n",
       "      <th>zoomed shop</th>\n",
       "      <th>zrm</th>\n",
       "      <th>zrm jedi</th>\n",
       "      <th>zzzzzz</th>\n",
       "      <th>zzzzzz wake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051429</td>\n",
       "      <td>0.051429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  00 meet  00 morning  00 said  00 star  00 telling  00 time  000  \\\n",
       "0  0.0      0.0         0.0      0.0      0.0         0.0      0.0  0.0   \n",
       "1  0.0      0.0         0.0      0.0      0.0         0.0      0.0  0.0   \n",
       "2  0.0      0.0         0.0      0.0      0.0         0.0      0.0  0.0   \n",
       "3  0.0      0.0         0.0      0.0      0.0         0.0      0.0  0.0   \n",
       "4  0.0      0.0         0.0      0.0      0.0         0.0      0.0  0.0   \n",
       "\n",
       "   000 000  000 5203  ...  zoe told  zoe wasn  zoe worms  zoomed  \\\n",
       "0      0.0       0.0  ...       0.0       0.0        0.0     0.0   \n",
       "1      0.0       0.0  ...       0.0       0.0        0.0     0.0   \n",
       "2      0.0       0.0  ...       0.0       0.0        0.0     0.0   \n",
       "3      0.0       0.0  ...       0.0       0.0        0.0     0.0   \n",
       "4      0.0       0.0  ...       0.0       0.0        0.0     0.0   \n",
       "\n",
       "   zoomed planted  zoomed shop  zrm  zrm jedi    zzzzzz  zzzzzz wake  \n",
       "0             0.0          0.0  0.0       0.0  0.000000     0.000000  \n",
       "1             0.0          0.0  0.0       0.0  0.051429     0.051429  \n",
       "2             0.0          0.0  0.0       0.0  0.000000     0.000000  \n",
       "3             0.0          0.0  0.0       0.0  0.000000     0.000000  \n",
       "4             0.0          0.0  0.0       0.0  0.000000     0.000000  \n",
       "\n",
       "[5 rows x 21876 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english',\n",
    "                        ngram_range=(1,2),\n",
    "                        min_df=1\n",
    "                       )\n",
    "# Create a vocabulary and get word counts per document\n",
    "ref_dtm = tfidf.fit_transform(reference_transcripts)\n",
    "\n",
    "features = tfidf.get_feature_names()\n",
    "#display(len(features), features[:50])\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "ref_dtm = pd.DataFrame(ref_dtm.todense(), columns=features)\n",
    "print(ref_dtm.shape)\n",
    "display(ref_dtm.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.2509\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0013\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 5.6224e-05\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 4.5460e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7f288e7310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ishape = ref_dtm.shape[1]\n",
    "# Create Model \n",
    "input_img = Input(shape=(ishape, ))\n",
    "\n",
    "x = Dense(1024)(input_img)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "\n",
    "x = Dense(128)(x)\n",
    "\n",
    "encoded = Dense(64)(x)\n",
    "\n",
    "x = Dense(128)(encoded)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "\n",
    "x = Dense(1024, activation='sigmoid')(x)\n",
    "decoded = Dense(ishape, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "rmodel = Model(input_img, decoded)\n",
    "rmodel.compile(loss='mse', optimizer=Adam(learning_rate=0.01))\n",
    "\n",
    "rmodel.fit(ref_dtm, ref_dtm, batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.20209184,  0.04470556, -0.02643825, ..., -0.38869217,\n",
       "        -0.25289783,  0.3736603 ],\n",
       "       [-0.2060911 ,  0.03171282,  0.00361387, ..., -0.38009903,\n",
       "        -0.22033359,  0.40168595],\n",
       "       [-0.21420166,  0.0238283 , -0.01913108, ..., -0.3860425 ,\n",
       "        -0.23833396,  0.39744115],\n",
       "       ...,\n",
       "       [-0.19514069,  0.04164192,  0.00533963, ..., -0.36928338,\n",
       "        -0.24332632,  0.35344464],\n",
       "       [-0.17044368,  0.04908935, -0.01003704, ..., -0.39402628,\n",
       "        -0.23826472,  0.38615996],\n",
       "       [-0.18238866,  0.05546333, -0.01705509, ..., -0.3944215 ,\n",
       "        -0.22832987,  0.3948711 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "encoded_ref_dtm = encoder.predict(ref_dtm)\n",
    "print(encoded_ref_dtm.shape)\n",
    "display(encoded_ref_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(doc):\n",
    "    vec = tfidf.transform([doc]).todense()\n",
    "    return encoder.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19826442  0.04513413 -0.02046486  0.09756547 -0.2748718   0.03936278\n",
      "   0.14605512 -0.3047451   0.01073894 -0.28902507  0.02956281 -0.2117703\n",
      "   0.1251549  -0.17435195  0.2520424  -0.11814192  0.18164337 -0.1066189\n",
      "   0.2782002   0.20693465  0.07913922 -0.0063188   0.06193272  0.11759567\n",
      "   0.35405606  0.38036788 -0.2576433   0.3372022   0.0667557   0.08950295\n",
      "   0.22679016 -0.01132899 -0.08049136 -0.05315205 -0.14614578  0.07444175\n",
      "   0.10548063  0.16759844 -0.20775996  0.30337945  0.15599829 -0.28564122\n",
      "  -0.25025833 -0.0936008   0.10519032 -0.04059128  0.13553895 -0.24569243\n",
      "  -0.14977553  0.01828392 -0.14496695 -0.00780673 -0.08907203  0.03033754\n",
      "  -0.06769946 -0.01583442  0.00582847  0.27126306 -0.06428409 -0.3049555\n",
      "   0.23848267 -0.39359912 -0.25245962  0.37320215]]\n"
     ]
    }
   ],
   "source": [
    "print(get_vector(google_transcripts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 21876)\n",
      "(165, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.19826454,  0.04513416, -0.02046483, ..., -0.393599  ,\n",
       "        -0.2524596 ,  0.37320215],\n",
       "       [-0.21015924,  0.02582057,  0.00458476, ..., -0.3815539 ,\n",
       "        -0.23613209,  0.40191668],\n",
       "       [-0.22374544,  0.02300805, -0.02269058, ..., -0.36834866,\n",
       "        -0.21772985,  0.4085685 ],\n",
       "       ...,\n",
       "       [-0.1956769 ,  0.03437908,  0.00996523, ..., -0.36309996,\n",
       "        -0.24307577,  0.3514322 ],\n",
       "       [-0.17025381,  0.05206164, -0.00691394, ..., -0.38990152,\n",
       "        -0.24444723,  0.3846683 ],\n",
       "       [-0.18380612,  0.0261796 , -0.02427699, ..., -0.38227686,\n",
       "        -0.2154612 ,  0.38472784]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.19826454,  0.04513416, -0.02046483, ..., -0.393599  ,\n",
       "        -0.2524596 ,  0.37320215],\n",
       "       [-0.21015924,  0.02582057,  0.00458476, ..., -0.3815539 ,\n",
       "        -0.23613209,  0.40191668],\n",
       "       [-0.22374544,  0.02300805, -0.02269058, ..., -0.36834866,\n",
       "        -0.21772985,  0.4085685 ],\n",
       "       ...,\n",
       "       [-0.1956769 ,  0.03437908,  0.00996523, ..., -0.36309996,\n",
       "        -0.24307577,  0.3514322 ],\n",
       "       [-0.17025381,  0.05206164, -0.00691394, ..., -0.38990152,\n",
       "        -0.24444723,  0.3846683 ],\n",
       "       [-0.18380612,  0.0261796 , -0.02427699, ..., -0.38227686,\n",
       "        -0.2154612 ,  0.38472784]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_encoded_dtm(transcripts):\n",
    "    dtm = tfidf.transform(transcripts).todense()\n",
    "    print(dtm.shape)\n",
    "    encoded_dtm = encoder.predict(dtm)\n",
    "    print(encoded_dtm.shape)\n",
    "    display(encoded_dtm)\n",
    "    return encoded_dtm\n",
    "\n",
    "encoded_google_dtm = get_encoded_dtm(google_transcripts)\n",
    "print(encoded_google_dtm.shape)\n",
    "display(encoded_google_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9996451]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([encoded_ref_dtm[0]], [encoded_google_dtm[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9996451, 0.9987583, 0.997483, 0.99449646, 0.99939185, 0.9998019, 0.99860454, 0.9993582, 0.99924624, 0.998436, 0.99978673, 0.99825656, 0.9986698, 0.9992837, 0.99858224, 0.99908984, 0.9959377, 0.99801373, 0.998486, 0.999632, 0.99927014, 0.9997517, 0.9990992, 0.99786437, 0.99996185, 0.99952483, 0.99991333, 0.9974342, 0.999168, 0.9996357, 0.9996481, 0.9993719, 0.9982471, 0.99945366, 0.9997749, 0.99926823, 0.9995072, 0.99873954, 0.9994596, 0.99968684, 0.9994625, 0.9993816, 0.9995769, 0.99904704, 0.9998536, 0.9982956, 0.99783766, 0.99931526, 0.9995854, 0.999362, 0.9994318, 0.9988151, 0.9993373, 0.999783, 0.9995308, 0.99857354, 0.9995926, 0.9949379, 0.9991705, 0.9994416, 0.9996401, 0.9996173, 0.9988978, 0.99549675, 0.9938877, 0.9995114, 0.9995142, 0.99974906, 0.9969016, 0.9997885, 0.9984046, 0.9986464, 0.9993672, 0.9990442, 0.9994365, 0.99990535, 0.99896353, 0.9988198, 0.9995659, 0.9985357, 0.99840367, 0.99985087, 0.9996724, 0.9994431, 0.99833024, 0.99830306, 0.99973166, 0.9996222, 0.9979898, 0.99844337, 0.999486, 0.9992734, 0.9990462, 0.99924666, 0.9988249, 0.9997276, 0.9994043, 0.9989472, 0.9986644, 0.99979925, 0.99797666, 0.99806726, 0.9997503, 0.9994553, 0.9996339, 0.9995742, 0.9985906, 0.99910086, 0.9994714, 0.99984324, 0.99984837, 0.99919397, 0.9992566, 0.99950653, 0.99924237, 0.9993545, 0.9995787, 0.9994407, 0.99943846, 0.9996045, 0.99991065, 0.99997544, 0.9991775, 0.9988431, 0.99880934, 0.99891275, 0.99922436, 0.9989713, 0.99957347, 0.9996227, 0.99949634, 0.99991703, 0.99949104, 0.99836576, 0.99939245, 0.9999149, 0.99909705, 0.99876285, 0.99956226, 0.99981844, 0.9994949, 0.9967685, 0.99971455, 0.9994495, 0.9996246, 0.9999093, 0.99930465, 0.999418, 0.9988741, 0.9998242, 0.99935555, 0.99868315, 0.9989714, 0.9996463, 0.99865854, 0.99951816, 0.9990519, 0.9983903, 0.99929965, 0.9998511, 0.9991073, 0.99912655, 0.99946, 0.99979365, 0.9965141]\n"
     ]
    }
   ],
   "source": [
    "def get_cossim(encoded_dtm):\n",
    "    cossim = []\n",
    "    for idx,ref in enumerate(encoded_ref_dtm):\n",
    "        cossim.append(cosine_similarity([ref], [encoded_dtm[idx]])[0][0]) \n",
    "    return cossim\n",
    "\n",
    "cossim = get_cossim(encoded_google_dtm)\n",
    "print(cossim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
