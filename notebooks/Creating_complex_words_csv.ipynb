{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creating_complex_words_csv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMWnNRNfXewe"
      },
      "source": [
        "# Import Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR1S2OghXjzO"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUTZIZ3CEyId"
      },
      "source": [
        "# Creating complex_words.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJZorl7HaPFF"
      },
      "source": [
        "Comparing the list of words to get the school level column to populate correctly did not work right. I opted to do it the long and difficult way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUTU3SO3WPM_"
      },
      "source": [
        "Each word seperated into the school levels they belong to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxwC46vWExtl"
      },
      "source": [
        "middle_school_level = \"abate, abide, abode, abrupt, absorb, abstain, absurd, abyss, accord, anathema, annex, bane, cogent, conduit, crass, dearth, debacle, defunct, dispel, edict, elicit, extant, foiled, foil, inane, mores, pert, quaint, rife, tome, trite, yoke, tutor, clout, accrue, acta, aft, akin, amid, ana, asp, aura, avid, awe, brute, chic, clad, coup, daft, dap, dire, duly, eon, ergo, eve, flux, heed, helm, hex, hind, hue, ire, keen, kiln, leer, lest, lug, lush, moot, ode, omit, poise, prod, prone, reel, riff, romp, rout, scant, sect, seep, sheen, shunt, silt, skew, skirr, sly, smelt, snare, sod, spiel, stern, stint, stout, stow, strut, subtle, sync, tacit, tact, taut, tether, thwart, toil, vat, vie, vigor, vivid, vying, wane, wary, weary, whim, woe, zeal\"\n",
        "high_school_level = \"aback, abalone, abased, abbot, abet, abettor, abeyance, abject, abhorrent, abridge, abrogate, abstruse, acarid, accede, accolade, accredit, acumen, admonish, alacrity, arboreal, ascetic, clamor, cleave, cobbler, consign, contrite, covet, despot, didactic, dirge, disrepute, dogmatic, dour, emollient, ephemeral, espouse, evince, fallacious, flagrant, fortuitous, fractious, gratuitous, hapless, impinge, impute, inimical, inoculate, instigate, inure, invective, knell, linchpin, litigant, maelstrom, maudlin, maverick, morass, nadir, panacea, paucity, pernicious, portent, profligate, prurient, puerile, relegate, remiss, reprieve, sanguine, sobriety, solicitous, staid, swarthy, travesty, trenchant, turpitude, veracity, vestige, vitriolic, winsome, zephyr, wily, tirade, grommet, sultry, accursed, accuser, acerbic, acerous, acetic, acme, acrid, adage, adduce, aegis, airfoil, alcove, alibi, allay, allude, alms, ambit, amble, amity, ancon, anent, animus, aphid, aptly, atone, awry, bask, bemoan, berate, bide, biome, boor, brash, brawl, butte, bygone, captor, cask, chaff, chard, chasm, chock, chroma, coax, cower, coy, crag, curt, dais, deft, delude, drab, droll, dupe, ebb, eke, elude, feign, fickle, flak, forgo, furl, garish, gauche, ghee, goad, gouge, heft, hew, hoax, hubris, illude, ingot, iota, jive, jolt, jot, knoll, laud, lave, lax, leery, lithe, loath, lob, lop, lunge, lurk, maim, meek, morsel, mull, naught, nook, obtuse, opus, placid, pleat, pout, privy, profuse, pry, puny, putrid, quell, rapt, reek, reform, relent, rend, repute, ruse, sate, shard, sigil, slat, sleuth, smirk, snafu, sneer, snide, snub, soiree, somber, sop, spew, spire, splay, stasis, stifle, stoke, suave, supine, surly, swath, tepid, topple, trawl, trice, trifle, trill, trope, unapt, usury, valor, verve, vouch, welt, whirl, wield, wile, writhe\"\n",
        "college_level = \"abase, abashed, abasia, abatis, abduct, abele, abhor, abiosis, abient, ablate, ablaze, abrade, abscind, absolve, accost, accosted, arrogate, bashful, carouse, connive, contusion, debunk, duplicity, elegy, emend, enervate, exhort, exigent, expunge, extol, fetter, garrulous, gourmand, iconoclast, inchoate, licentious, modicum, neophyte, noisome, ostracism, palliate, pariah, pejorative, penurious, pithy, platitude, plaudit, plenitude, potentate, presage, probity, proclivity, protean, quandary, reprobate, scurrilous, stolid, subjugate, surfeit, torpid, truculent, nauseant, addend, acerbate, acerose, acetous, achene, aciniform, acquiesce, acrostic, adit, adulate, aerate, affix, antic, arete, argot, balk, bequeath, bungle, callow, careen, chortle, cohere, collude, comity, contort, contuse, couth, cowl, cyborg, dally, decry, dote, drawl, dyad, effigy, elate, exult, frill, gnash, gnaw, gruff, gyro, husk, imbue, inapt, knave, lank, malady, maraud, maw, ombre, plait, preen, pylon, pyre, quash, rancor, rasp, recant, redact, refract, resile, revile, rile, scoff, scowl, seethe, shirk, sidle, sinew, singe, slosh, souse, squall, sunder, swathe, tatter, teem, tousle, tuft, vapid, wiry\"\n",
        "post_college_level = \"abaft, abamp, abampere, abash, abaxial, abbacy, abbess, abduce, abducent, abductee, abductor, abelmosk, abeyant, abjure, abnegate, abscond, acclivity, accroach, adumbrate, aggrandize, beguile, bilk, cajole, calumny, cavort, congruity, cupidity, debauch, discomfit, enfranchise, equivocal, execrable, expiate, expurgate, fatuous, mawkish, obdurate, officious, pellucid, phlegmatic, proscribe, quixotic, solipsism, toady, umbrage, upbraid, vilify, fipple, accustom, acedia, acerbity, acicular, aciculate, acolyte, acquit, addle, adjoin, adjure, agog, amuck, apiary, appall, avow, bawl, chide, conjoin, conk, dactyl, decoct, deify, divvy, doff, doily, edify, embroil, espy, exude, flay, fleck, flub, guck, gyre, hovel, irk, jeer, jibe, jinx, jowl, laze, liquefy, mewl, miff, mope, perplex, pilfer, posy, primp, qualm, quip, quirk, rebuff, reify, schlep, skulk, spry, vex, waft, yowl\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWHa_1VFZ21H"
      },
      "source": [
        "Splitting each string to make lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UML_y-Isu8qJ"
      },
      "source": [
        "middle_school_level = middle_school_level.split(', ')\n",
        "high_school_level = high_school_level.split(', ')\n",
        "college_level = college_level.split(', ')\n",
        "post_college_level = post_college_level.split(', ')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KflbHgI-Z8ef"
      },
      "source": [
        "Making each list into it's own dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jVWY9ZQFpUM"
      },
      "source": [
        "df = pd.DataFrame(middle_school_level, columns=[\"word\"])\n",
        "df_high = pd.DataFrame(high_school_level, columns=[\"word\"])\n",
        "df_college = pd.DataFrame(college_level, columns=[\"word\"])\n",
        "df_post = pd.DataFrame(post_college_level, columns=[\"word\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt06GJPqaEq9"
      },
      "source": [
        "Assigning the school level tag for each dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTyLHx5zWKGP"
      },
      "source": [
        "df['school level'] = \"middle school\"\n",
        "df_high['school level'] = \"high school\"\n",
        "df_college['school level'] = \"college\"\n",
        "df_post['school level'] = \"post college\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H_Pb5TuagjR"
      },
      "source": [
        "Assigning the complexity score based on the school level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T6Lu5vaXxKj"
      },
      "source": [
        "df['complexity'] = 14\n",
        "df_high['complexity'] = 16\n",
        "df_college['complexity'] = 18\n",
        "df_post['complexity'] = 20"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GauEAQXBalwt"
      },
      "source": [
        "Concatenating the dataframes into one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_BcaNmNWcIp"
      },
      "source": [
        "frames = [df, df_high, df_college, df_post]\n",
        "result = pd.concat(frames)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pVWIauoOXoV8",
        "outputId": "940c212e-875b-4b10-c97b-359287c9010f"
      },
      "source": [
        "result"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>school level</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abate</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abide</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abode</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abrupt</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>absorb</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>skulk</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>spry</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>vex</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>waft</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>yowl</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>604 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       word   school level  complexity\n",
              "0     abate  middle school          14\n",
              "1     abide  middle school          14\n",
              "2     abode  middle school          14\n",
              "3    abrupt  middle school          14\n",
              "4    absorb  middle school          14\n",
              "..      ...            ...         ...\n",
              "103   skulk   post college          20\n",
              "104    spry   post college          20\n",
              "105     vex   post college          20\n",
              "106    waft   post college          20\n",
              "107    yowl   post college          20\n",
              "\n",
              "[604 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG0R4JlYa6gc"
      },
      "source": [
        "Making sure that there aren't any duplicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of0wBLa7Z-4J"
      },
      "source": [
        "result = result.drop_duplicates(\"word\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxg6ArKbbAWr"
      },
      "source": [
        "Same amount of rows shows that there were no duplicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "AJH15eQDjRhP",
        "outputId": "7dca1c61-d43e-417a-a61c-eb1ef0c6db4a"
      },
      "source": [
        "result"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>school level</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abate</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abide</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abode</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abrupt</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>absorb</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>skulk</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>spry</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>vex</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>waft</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>yowl</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>604 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       word   school level  complexity\n",
              "0     abate  middle school          14\n",
              "1     abide  middle school          14\n",
              "2     abode  middle school          14\n",
              "3    abrupt  middle school          14\n",
              "4    absorb  middle school          14\n",
              "..      ...            ...         ...\n",
              "103   skulk   post college          20\n",
              "104    spry   post college          20\n",
              "105     vex   post college          20\n",
              "106    waft   post college          20\n",
              "107    yowl   post college          20\n",
              "\n",
              "[604 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aPpQk6WbFV1"
      },
      "source": [
        "I tried to sort the whole dataframe alphabetically, but that didn't work correctly either. I compiled all the words into their respective catagory based on the first letter of the word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqgvW5tJlBVc"
      },
      "source": [
        "a_words = [\"aback\", \"abaft\", \"abalone\", \"abamp\", \"abampere\", \"abase\", \"abased\", \"abash\", \"abashed\", \"abasia\", \"abate\", \"abatis\", \"abaxial\", \"abbacy\", \"abbess\", \"abbot\", \"abduce\", \"abduct\", \"abducent\", \"abductee\", \"abductor\", \"abele\", \"abelmosk\", \"abet\", \"abettor\", \"abeyance\", \"abeyant\", \"abhor\", \"abject\", \"abhorrent\", \"abjure\", \"abide\", \"abiosis\", \"abient\", \"ablate\", \"ablaze\", \"abnegate\", \"abode\", \"abrade\", \"abridge\", \"abrogate\", \"abrupt\", \"abscind\", \"absolve\", \"absorb\", \"abscond\", \"abstain\", \"abstruse\", \"absurd\", \"abyss\", \"acarid\", \"accede\", \"acclivity\", \"accolade\", \"accord\", \"accost\", \"accosted\", \"accredit\", \"accroach\", \"accrue\", \"acumen\", \"admonish\", \"adumbrate\", \"aggrandize\", \"alacrity\", \"anathema\", \"annex\", \"arboreal\", \"arrogate\", \"ascetic\", \"accursed\", \"accuser\",  \"accustom\", \"acedia\", \"acerbic\", \"acerbate\", \"acerbity\", \"acerose\", \"acerous\", \"acetic\", \"acetous\", \"achene\", \"acicular\", \"aciculate\", \"aciniform\", \"acme\", \"acolyte\", \"acquiesce\", \"acquit\", \"acrid\", \"acrostic\", \"acta\", \"adage\", \"addle\", \"adduce\", \"adit\", \"adjoin\", \"adjure\", \"adulate\", \"aegis\", \"aerate\", \"affix\", \"aft\", \"agog\", \"airfoil\", \"akin\", \"alcove\", \"alibi\", \"allay\", \"allude\", \"alms\", \"ambit\", \"amble\", \"amid\", \"amity\", \"amuck\", \"ana\", \"ancon\", \"anent\", \"animus\", \"antic\", \"aphid\", \"apiary\", \"appall\", \"aptly\", \"arete\", \"argot\", \"asp\", \"atone\", \"aura\", \"avid\", \"avow\", \"awe\", \"awry\", \"addend\"]\n",
        "b_words = [\"bane\", \"bashful\", \"beguile\", \"bilk\", \"balk\", \"bask\", \"bawl\", \"bemoan\", \"bequeath\", \"berate\", \"bide\", \"biome\", \"boor\", \"brash\", \"brawl\", \"brute\", \"bungle\", \"butte\", \"bygone\"]\n",
        "c_words = [\"cajole\", \"calumny\", \"carouse\", \"cavort\", \"clamor\", \"cleave\", \"cobbler\", \"cogent\", \"conduit\", \"congruity\", \"connive\", \"consign\", \"contusion\", \"contrite\", \"covet\", \"cupidity\", \"crass\", \"clout\", \"callow\", \"captor\", \"careen\", \"cask\", \"chaff\", \"chard\", \"chasm\", \"chic\", \"chide\", \"chock\", \"chortle\", \"chroma\", \"clad\", \"coax\", \"cohere\", \"collude\", \"comity\", \"conjoin\", \"conk\", \"contort\", \"contuse\", \"coup\", \"cower\", \"cowl\", \"coy\", \"crag\", \"curt\", \"couth\", \"cyborg\"]\n",
        "d_words = [\"dap\", \"deify\", \"dactyl\", \"duly\", \"dupe\", \"deft\", \"decry\", \"divvy\", \"dire\", \"delude\", \"doily\", \"dote\", \"drab\", \"drawl\", \"dyad\", \"droll\", \"daft\", \"dally\", \"dais\", \"dearth\", \"decoct\", \"debacle\", \"debauch\", \"debunk\", \"defunct\", \"despot\", \"didactic\", \"dirge\", \"discomfit\", \"dispel\", \"disrepute\", \"dogmatic\", \"dour\", \"duplicity\", \"doff\"]\n",
        "e_words = [\"edict\", \"elegy\", \"elicit\", \"emend\", \"emollient\", \"enervate\", \"enfranchise\", \"ephemeral\", \"equivocal\", \"espouse\", \"evince\", \"exhort\", \"execrable\", \"exigent\", \"expiate\", \"expunge\", \"extol\", \"extant\", \"expurgate\", \"ebb\", \"edify\", \"effigy\", \"eke\", \"elate\", \"elude\", \"embroil\", \"eon\", \"ergo\", \"espy\", \"eve\", \"exude\", \"exult\"]\n",
        "f_words = [\"fallacious\", \"fatuous\", \"fetter\", \"flagrant\", \"foiled\", \"foil\", \"fortuitous\", \"fractious\", \"fipple\", \"feign\", \"fickle\", \"flak\", \"flay\", \"fleck\", \"flub\", \"flux\", \"forgo\", \"frill\", \"furl\"]\n",
        "g_words = [\"garrulous\", \"gourmand\", \"gratuitous\", \"grommet\", \"garish\", \"gauche\", \"ghee\", \"gnash\", \"gnaw\", \"goad\", \"gouge\", \"gruff\", \"guck\", \"gyre\", \"gyro\"]\n",
        "h_words = [\"hapless\", \"heed\", \"heft\", \"helm\", \"hew\", \"hex\", \"hind\", \"hoax\", \"hovel\", \"hubris\", \"hue\", \"husk\"]\n",
        "i_words = [\"iconoclast\", \"impinge\", \"impute\", \"inane\", \"inchoate\", \"inimical\", \"inoculate\", \"instigate\", \"inure\", \"invective\", \"illude\", \"imbue\", \"inapt\", \"ingot\", \"iota\", \"ire\", \"irk\"]\n",
        "j_words = [\"jeer\", \"jibe\", \"jinx\", \"jive\", \"jolt\", \"jot\", \"jowl\"]\n",
        "k_words = [\"knell\", \"keen\", \"kiln\", \"knave\", \"knoll\"]\n",
        "l_words = [\"licentious\", \"linchpin\", \"litigant\", \"lank\", \"laud\", \"lave\", \"lax\", \"laze\", \"leer\", \"leery\", \"lest\", \"liquefy\", \"lithe\", \"loath\", \"lob\", \"lop\", \"lug\", \"lunge\", \"lurk\", \"lush\"]\n",
        "m_words = [\"maelstrom\", \"maudlin\", \"maverick\", \"mawkish\", \"modicum\", \"morass\", \"mores\", \"maim\", \"malady\", \"maraud\", \"maw\", \"meek\", \"mewl\", \"miff\", \"moot\", \"mope\", \"morsel\", \"mull\"]\n",
        "n_words = [\"nadir\", \"neophyte\", \"noisome\", \"nauseant\", \"naught\", \"nook\"]\n",
        "o_words = [\"obdurate\", \"officious\", \"ostracism\", \"obtuse\", \"ode\", \"ombre\", \"omit\", \"opus\"]\n",
        "p_words = [\"palliate\", \"panacea\", \"pariah\", \"paucity\", \"pejorative\", \"pellucid\", \"penurious\", \"pert\", \"pernicious\", \"phlegmatic\", \"pithy\", \"platitude\", \"plaudit\", \"plenitude\", \"portent\", \"potentate\", \"presage\", \"probity\", \"proclivity\", \"profligate\", \"proscribe\", \"protean\", \"prurient\", \"puerile\", \"perplex\", \"pilfer\", \"placid\", \"plait\", \"pleat\", \"poise\", \"posy\", \"pout\", \"preen\", \"primp\", \"privy\", \"prod\", \"profuse\", \"prone\", \"pry\", \"puny\", \"putrid\", \"pylon\", \"pyre\"]\n",
        "q_words = [\"quaint\", \"quixotic\", \"quandary\", \"qualm\", \"quash\", \"quell\", \"quip\", \"quirk\"]\n",
        "r_words = [\"relegate\", \"remiss\", \"reprieve\", \"reprobate\", \"rife\", \"rancor\", \"rapt\", \"rasp\", \"rebuff\", \"recant\", \"redact\", \"reek\", \"reel\", \"reform\", \"refract\", \"reify\", \"relent\", \"rend\", \"repute\", \"resile\", \"revile\", \"riff\", \"rile\", \"romp\", \"rout\", \"ruse\"]\n",
        "s_words = [\"sanguine\", \"scurrilous\", \"sobriety\", \"solicitous\", \"solipsism\", \"staid\", \"stolid\", \"subjugate\", \"surfeit\", \"swarthy\", \"sultry\", \"sate\", \"scant\", \"schlep\", \"scoff\", \"scowl\", \"sect\", \"seep\", \"seethe\", \"shard\", \"sheen\", \"shirk\", \"shunt\", \"sidle\", \"sigil\", \"silt\", \"sinew\", \"singe\", \"skew\", \"skirr\", \"skulk\", \"slat\", \"sleuth\", \"slosh\", \"sly\", \"smelt\", \"smirk\", \"snafu\", \"snare\", \"sneer\", \"snide\", \"snub\", \"sod\", \"soiree\", \"somber\", \"sop\", \"souse\", \"spew\", \"spiel\", \"spire\", \"splay\", \"spry\", \"squall\", \"stasis\", \"stern\", \"stifle\", \"stint\", \"stoke\", \"stout\", \"stow\", \"strut\", \"suave\", \"subtle\", \"sunder\", \"supine\", \"surly\", \"swath\", \"swathe\", \"sync\"]\n",
        "t_words = [\"tome\", \"toady\", \"torpid\", \"travesty\", \"trenchant\", \"trite\", \"truculent\", \"turpitude\", \"tirade\", \"tutor\", \"tacit\", \"tact\", \"tatter\", \"taut\", \"teem\", \"tepid\", \"tether\", \"thwart\", \"toil\", \"topple\", \"tousle\", \"trawl\", \"trice\", \"trifle\", \"trill\", \"trope\", \"tuft\"]\n",
        "u_words = [\"umbrage\", \"upbraid\", \"unapt\", \"usury\"]\n",
        "v_words = [\"veracity\", \"vestige\", \"vilify\", \"vitriolic\", \"valor\", \"vapid\", \"vat\", \"verve\", \"vex\", \"vie\", \"vigor\", \"vivid\", \"vouch\", \"vying\"]\n",
        "w_words = [\"winsome\", \"wily\", \"waft\", \"wane\", \"wary\", \"weary\", \"welt\", \"whim\", \"whirl\", \"wield\", \"wile\", \"wiry\", \"woe\", \"writhe\"]\n",
        "y_words = [\"yoke\", \"yowl\"]\n",
        "z_words = [\"zephyr\", \"zeal\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB19SI_Ebc7Y"
      },
      "source": [
        "Then sorted each list individually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ8zE9LlpMDB"
      },
      "source": [
        "a_words.sort()\n",
        "b_words.sort()\n",
        "c_words.sort()\n",
        "d_words.sort()\n",
        "e_words.sort()\n",
        "f_words.sort()\n",
        "g_words.sort()\n",
        "h_words.sort()\n",
        "i_words.sort()\n",
        "j_words.sort()\n",
        "k_words.sort()\n",
        "l_words.sort()\n",
        "m_words.sort()\n",
        "n_words.sort()\n",
        "o_words.sort()\n",
        "p_words.sort()\n",
        "q_words.sort()\n",
        "r_words.sort()\n",
        "s_words.sort()\n",
        "t_words.sort()\n",
        "u_words.sort()\n",
        "v_words.sort()\n",
        "w_words.sort()\n",
        "y_words.sort()\n",
        "z_words.sort()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WTAVuvUbisj"
      },
      "source": [
        "Combined all of the lists into one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJp90RcTotYd"
      },
      "source": [
        "alphabetically_sorted_words = a_words + b_words + c_words + d_words + e_words + f_words + g_words + h_words + i_words + j_words + k_words + l_words + m_words + n_words + o_words + p_words + q_words + r_words + s_words + t_words + u_words + v_words + w_words + y_words + z_words"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odWxPXTNbli0"
      },
      "source": [
        "Made the combined list into a new dataframe and checked to make sure there were no duplicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "pjWx8HV4p8p8",
        "outputId": "ac8d3a90-d39e-4354-9e7e-51a4b453bfe4"
      },
      "source": [
        "alpha_df = pd.DataFrame(alphabetically_sorted_words, columns=['word'])\n",
        "print(alpha_df.value_counts())\n",
        "alpha_df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word      \n",
            "zephyr        1\n",
            "dearth        1\n",
            "dally         1\n",
            "dais          1\n",
            "daft          1\n",
            "             ..\n",
            "pernicious    1\n",
            "penurious     1\n",
            "pellucid      1\n",
            "pejorative    1\n",
            "aback         1\n",
            "Length: 604, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aback</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abaft</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abalone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abamp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abampere</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>writhe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>yoke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>yowl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>zeal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>zephyr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>604 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         word\n",
              "0       aback\n",
              "1       abaft\n",
              "2     abalone\n",
              "3       abamp\n",
              "4    abampere\n",
              "..        ...\n",
              "599    writhe\n",
              "600      yoke\n",
              "601      yowl\n",
              "602      zeal\n",
              "603    zephyr\n",
              "\n",
              "[604 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PWfMCA1b6x-"
      },
      "source": [
        "Combined the lists of words by school level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTz4lmZ3Zw6G"
      },
      "source": [
        "levels_added_together = middle_school_level + high_school_level + college_level + post_college_level"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3F4Egz2cD3R"
      },
      "source": [
        "Combined all of the lists together to insure that there were exactly two of each word. Meaning that I had the same words in both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-JZvMpSFpQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50021d70-31b5-45f2-f66e-5d130aa51315"
      },
      "source": [
        "checking_for_missing_words = alphabetically_sorted_words + levels_added_together\n",
        "checking_for_missing_words_df = pd.DataFrame(checking_for_missing_words, columns=['word'])\n",
        "print(checking_for_missing_words_df.value_counts())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word      \n",
            "zephyr        2\n",
            "dearth        2\n",
            "dally         2\n",
            "dais          2\n",
            "daft          2\n",
            "             ..\n",
            "pernicious    2\n",
            "penurious     2\n",
            "pellucid      2\n",
            "pejorative    2\n",
            "aback         2\n",
            "Length: 604, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAeJXe0kcQrU"
      },
      "source": [
        "I then reindexed the result dataframe to match the order of the alphabetically sorted dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbi7NdInqGpE"
      },
      "source": [
        "result = result.set_index('word')\n",
        "result = result.reindex(index=alpha_df['word'])\n",
        "result = result.reset_index()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgf40-mccfi"
      },
      "source": [
        "Again insuring that there are only one of each word in my result dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9ZtJQZZq5wl",
        "outputId": "a75a33e8-3bd4-4c91-aec0-b6890c80c92f"
      },
      "source": [
        "result['word'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "opus         1\n",
              "proscribe    1\n",
              "nauseant     1\n",
              "divvy        1\n",
              "ire          1\n",
              "            ..\n",
              "apiary       1\n",
              "hoax         1\n",
              "accost       1\n",
              "pyre         1\n",
              "awry         1\n",
              "Name: word, Length: 604, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1678kBgtcyva"
      },
      "source": [
        "Just checking that everything looks correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDlF7xVcRV9u",
        "outputId": "6af76fe5-884a-4c23-83f0-f80991afbb8d"
      },
      "source": [
        "result['complexity'].value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16    237\n",
              "18    144\n",
              "14    115\n",
              "20    108\n",
              "Name: complexity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjVuO4vtUI2x",
        "outputId": "7d18dd18-887c-465a-cae0-2cb5628c38a8"
      },
      "source": [
        "result['complexity']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      16\n",
              "1      20\n",
              "2      16\n",
              "3      20\n",
              "4      20\n",
              "       ..\n",
              "599    16\n",
              "600    14\n",
              "601    20\n",
              "602    14\n",
              "603    16\n",
              "Name: complexity, Length: 604, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lu5iWC0c3Wi"
      },
      "source": [
        "Converting my result dataframe to the complex_words.csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziCIa_kCfTiA"
      },
      "source": [
        "result.to_csv(\"complex_words.csv\", index=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF8yShtxc_m-"
      },
      "source": [
        "Checking that the csv reads correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6un5S5crnT73"
      },
      "source": [
        "complex_words = pd.read_csv('/content/complex_words.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6B0bAClIuYu6",
        "outputId": "d397c543-44f1-499a-81b4-637853bb8e07"
      },
      "source": [
        "complex_words"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>school level</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aback</td>\n",
              "      <td>high school</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abaft</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abalone</td>\n",
              "      <td>high school</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abamp</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abampere</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>writhe</td>\n",
              "      <td>high school</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>yoke</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>yowl</td>\n",
              "      <td>post college</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>zeal</td>\n",
              "      <td>middle school</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>zephyr</td>\n",
              "      <td>high school</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>604 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         word   school level  complexity\n",
              "0       aback    high school          16\n",
              "1       abaft   post college          20\n",
              "2     abalone    high school          16\n",
              "3       abamp   post college          20\n",
              "4    abampere   post college          20\n",
              "..        ...            ...         ...\n",
              "599    writhe    high school          16\n",
              "600      yoke  middle school          14\n",
              "601      yowl   post college          20\n",
              "602      zeal  middle school          14\n",
              "603    zephyr    high school          16\n",
              "\n",
              "[604 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}