{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------\n",
      "absl-py                      1.0.0\n",
      "aiohttp                      3.8.1\n",
      "aiohttp-cors                 0.7.0\n",
      "aioredis                     1.3.1\n",
      "aiosignal                    1.2.0\n",
      "ansicon                      1.89.0\n",
      "argon2-cffi                  21.1.0\n",
      "astunparse                   1.6.3\n",
      "async-timeout                4.0.1\n",
      "attrs                        21.2.0\n",
      "backcall                     0.2.0\n",
      "bleach                       4.1.0\n",
      "blessed                      1.19.0\n",
      "cachetools                   4.2.4\n",
      "certifi                      2021.10.8\n",
      "cffi                         1.15.0\n",
      "charset-normalizer           2.0.7\n",
      "click                        8.0.3\n",
      "colorama                     0.4.4\n",
      "colorful                     0.5.4\n",
      "cycler                       0.11.0\n",
      "debugpy                      1.5.1\n",
      "decorator                    5.1.0\n",
      "defusedxml                   0.7.1\n",
      "Deprecated                   1.2.13\n",
      "entrypoints                  0.3\n",
      "filelock                     3.4.0\n",
      "flatbuffers                  2.0\n",
      "frozenlist                   1.2.0\n",
      "gast                         0.4.0\n",
      "google-api-core              2.3.0\n",
      "google-auth                  2.3.3\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "googleapis-common-protos     1.54.0\n",
      "gpustat                      1.0.0b1\n",
      "grpcio                       1.41.1\n",
      "h5py                         3.5.0\n",
      "hiredis                      2.0.0\n",
      "idna                         3.3\n",
      "ipykernel                    6.5.0\n",
      "ipython                      7.29.0\n",
      "ipython-genutils             0.2.0\n",
      "ipywidgets                   7.6.5\n",
      "jedi                         0.18.0\n",
      "Jinja2                       3.0.3\n",
      "jinxed                       1.1.0\n",
      "jsonschema                   4.2.1\n",
      "jupyter                      1.0.0\n",
      "jupyter-client               7.0.6\n",
      "jupyter-console              6.4.0\n",
      "jupyter-core                 4.9.1\n",
      "jupyterlab-pygments          0.1.2\n",
      "jupyterlab-widgets           1.0.2\n",
      "keras                        2.7.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.3.2\n",
      "libclang                     12.0.0\n",
      "llvmlite                     0.38.0\n",
      "Markdown                     3.3.4\n",
      "MarkupSafe                   2.0.1\n",
      "matplotlib                   3.4.3\n",
      "matplotlib-inline            0.1.3\n",
      "mistune                      0.8.4\n",
      "msgpack                      1.0.3\n",
      "multidict                    5.2.0\n",
      "nbclient                     0.5.8\n",
      "nbconvert                    6.3.0\n",
      "nbformat                     5.1.3\n",
      "nest-asyncio                 1.5.1\n",
      "notebook                     6.4.5\n",
      "numba                        0.55.1\n",
      "numpy                        1.21.4\n",
      "nvidia-ml-py3                7.352.0\n",
      "oauthlib                     3.1.1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'E:\\lambda\\labs\\ds-test-2\\venv2\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "opencensus                   0.8.0\n",
      "opencensus-context           0.1.2\n",
      "opencv-python                4.5.4.58\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    21.2\n",
      "pandas                       1.3.4\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.2\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       8.4.0\n",
      "pip                          21.2.4\n",
      "prometheus-client            0.12.0\n",
      "prompt-toolkit               3.0.22\n",
      "protobuf                     3.19.1\n",
      "psutil                       5.8.0\n",
      "py-spy                       0.3.11\n",
      "pyasn1                       0.4.8\n",
      "pyasn1-modules               0.2.8\n",
      "pycparser                    2.21\n",
      "Pygments                     2.10.0\n",
      "pyparsing                    2.4.7\n",
      "pyrsistent                   0.18.0\n",
      "python-dateutil              2.8.2\n",
      "pytz                         2021.3\n",
      "pywin32                      302\n",
      "pywinpty                     1.1.5\n",
      "PyYAML                       6.0\n",
      "pyzmq                        22.3.0\n",
      "qtconsole                    5.2.0\n",
      "QtPy                         1.11.2\n",
      "ray                          1.9.0\n",
      "redis                        4.0.2\n",
      "requests                     2.26.0\n",
      "requests-oauthlib            1.3.0\n",
      "rsa                          4.7.2\n",
      "Send2Trash                   1.8.0\n",
      "setuptools                   58.2.0\n",
      "six                          1.16.0\n",
      "smart-open                   5.2.1\n",
      "tabulate                     0.8.9\n",
      "tensorboard                  2.7.0\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.0\n",
      "tensorboardX                 2.4.1\n",
      "tensorflow                   2.7.0\n",
      "tensorflow-estimator         2.7.0\n",
      "tensorflow-gpu               2.7.0\n",
      "tensorflow-io-gcs-filesystem 0.22.0\n",
      "termcolor                    1.1.0\n",
      "terminado                    0.12.1\n",
      "testpath                     0.5.0\n",
      "tornado                      6.1\n",
      "traitlets                    5.1.1\n",
      "typer                        0.4.0\n",
      "typing-extensions            3.10.0.2\n",
      "urllib3                      1.26.7\n",
      "wcwidth                      0.2.5\n",
      "webencodings                 0.5.1\n",
      "Werkzeug                     2.0.2\n",
      "wheel                        0.37.0\n",
      "widgetsnbextension           3.5.2\n",
      "wrapt                        1.13.3\n",
      "yarl                         1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was executed on:\n",
    "- Windows 10\n",
    "- Ryzen 3900x\n",
    "- 32 GB ram\n",
    "- Nvidia 3080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research question:\n",
    "is it possible using the sythetic dataset provided by generate.py and samples of user input provided by story_photo_transformer.py to generate coordinates with less than 8pix mean average error.\n",
    "\n",
    "---\n",
    "\n",
    "## Hypothesis\n",
    "Adding convolution layers to the beginning of the model will improve MAE to below baseline levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#shared experiment variables\n",
    "global_batch_size = 96\n",
    "global_epochs = 1000\n",
    "global_learning_rate =.00015\n",
    "\n",
    "# experiment groups\n",
    "# experiment group Q will test networks that have had their dense layers initialized to constants\n",
    "group_Q = []\n",
    "group_Q.append({\n",
    "    \"experiment_label\" :\"q1\",\n",
    "    \"experiment_desc\":\"constant initialization 1 conv layer, 3 FC Dense of 32 Height\",\n",
    "    \"num_conv\" :\"1\",\n",
    "    \"initialization\":\"constant\",\n",
    "})\n",
    "group_Q.append({\n",
    "    \"experiment_label\" :\"q2\",\n",
    "    \"experiment_desc\":\"constant initialization 2 conv layer, 3 FC Dense of 32 Height\",\n",
    "    \"num_conv\" :\"2\",\n",
    "    \"initialization\":\"constant\",\n",
    "})\n",
    "group_Q.append({\n",
    "    \"experiment_label\" :\"q3\",\n",
    "    \"experiment_desc\":\"constant initialization 3 conv layer, 3 FC Dense of 32 Height\",\n",
    "    \"num_conv\" :\"3\",\n",
    "    \"initialization\":\"constant\",\n",
    "})\n",
    "# experiment group R will test networks that have the default random initialization\n",
    "group_R = []\n",
    "group_R.append({\n",
    "    \"experiment_label\" :\"r1\",\n",
    "    \"experiment_desc\":\"default random initialization 1 conv layer, 3 FC Dense of 32 Height\",\n",
    "    \"num_conv\" :\"1\",\n",
    "    \"initialization\":\"default\",\n",
    "})\n",
    "group_R.append({\n",
    "    \"experiment_label\" :\"r2\",\n",
    "    \"experiment_desc\":\"default random initialization 2 conv layer, 3 FC Dense of 32 Height\",\n",
    "    \"num_conv\" :\"2\",\n",
    "    \"initialization\":\"default\",\n",
    "})\n",
    "group_R.append({\n",
    "    \"experiment_label\" :\"r3\",\n",
    "    \"experiment_desc\":\"default random initialization 3 conv layer, 3 FC Dense of 32 Height\",\n",
    "    \"num_conv\" :\"3\",\n",
    "    \"initialization\":\"default\",\n",
    "})\n",
    "experiments = group_Q+group_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# graphing function\n",
    "def display_history(hist,label):\n",
    "    # plot history\n",
    "\n",
    "    loss_p = hist.history['loss']\n",
    "    val_loss_p = hist.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(loss_p, label='MAE (training data)')\n",
    "    plt.title(label)\n",
    "    plt.ylabel('MAE value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    #plt.yscale('log',base=2)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(val_loss_p, label='MAE (validation data)')\n",
    "    plt.title(label)\n",
    "    plt.ylabel('MAE value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    #plt.yscale('log',base=2)\n",
    "    plt.show()\n",
    "\n",
    "    for i in range(0,len(hist.history['val_loss']),1000):\n",
    "        min_loss = np.array(hist.history['loss'])[:i+1000].min()\n",
    "        min_val =  np.array(hist.history['val_loss'])[:i+1000].min()\n",
    "        print(f'By epoch {i+1000} The minimum MAE achieved by the training was {min_loss}.')\n",
    "        print(f'By epoch {i+1000} The minimum MAE achieved on the real data was {min_val}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of data [], 0 records\n",
      "Sythetic  data contains 0 records.\n",
      "Real data contains 15 records.\n"
     ]
    }
   ],
   "source": [
    "## section that handles loading data\n",
    "import os\n",
    "os.add_dll_directory(r'e:\\cuda\\bin')\n",
    "\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# this is the path to the synthetic data generated by generate.py, you may need to change this to match your system.\n",
    "data_dir =r'..\\..\\..\\models\\synthetic_data\\synthetic_data_for_pipeline_transform\\data\\*\\*'\n",
    "example_data_files = glob.glob(data_dir)[0:]\n",
    "print(f'Example of data {example_data_files[0:3]}, {len(example_data_files)} records')\n",
    "\n",
    "# load each of the X_input files using opencv and convert to BGR colorspace as required by opencv\n",
    "X_train =[ cv2.cvtColor(cv2.imread(x),cv2.COLOR_RGB2BGR) for x in example_data_files if \"X_input\" in x ]\n",
    "# load point data for each record\n",
    "y_train =[ json.loads( open(y,'rb').read() )[\"y_label_points\"] for y in example_data_files if \".json\" in y ]\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train).reshape((X_train.shape[0],8))\n",
    "\n",
    "# load real data\n",
    "# this loads actual recorded user data that optimally we would like to predict with zero error.\n",
    "\n",
    "path_real = r'..\\..\\..\\data\\transcribed_stories\\*\\*\\phase0\\*'\n",
    "real_set=glob.glob(path_real)\n",
    "# load and convert the data\n",
    "X_real =np.array([ cv2.cvtColor(cv2.imread(x),cv2.COLOR_RGB2BGR) for x in real_set if \"X_input\" in x ])\n",
    "y_real =[ json.loads(open(y,'rb').read() )[\"y_label_points\"] for y in real_set if \".json\" in y ]\n",
    "y_real = np.array(y_real).reshape((X_real.shape[0],8))\n",
    "\n",
    "assert (X_real.shape[0]==y_real.shape[0])\n",
    "print(f'Sythetic  data contains {X_train.shape[0]} records.')\n",
    "print(f'Real data contains {X_real.shape[0]} records.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_experiment_model(num_conv,initialization):\n",
    "    if initialization == \"constant\":\n",
    "        c_init = keras.initializers.Constant(.004)\n",
    "        b_init = keras.initializers.Constant(.004)\n",
    "    else:\n",
    "        c_init=None\n",
    "        b_init=None\n",
    "\n",
    "    img_inputs = keras.Input(shape=(256, 256-64, 3))\n",
    "    x = img_inputs\n",
    "\n",
    "    for _ in range(int(num_conv)):\n",
    "        x = layers.Conv2D(32,(3,3),(2,2))(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = layers.MaxPool2D(strides=(2,2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32, activation=\"relu\",dtype=\"float32\",kernel_initializer=c_init,bias_initializer=b_init)(x)\n",
    "    x = layers.Dense(32, activation=\"relu\",dtype=\"float32\",kernel_initializer=c_init,bias_initializer=b_init)(x)\n",
    "    x = layers.Dense(32, activation=\"relu\",dtype=\"float32\",kernel_initializer=c_init,bias_initializer=b_init)(x)\n",
    "\n",
    "    outputs = layers.Dense(8,activation=\"relu\",kernel_initializer=c_init,bias_initializer=b_init)(x)\n",
    "\n",
    "    model = keras.Model(inputs=img_inputs, outputs=outputs, name=\"FC_Model\")\n",
    "    model.summary()\n",
    "    model.compile(loss=\"MAE\",optimizer=tf.keras.optimizers.Adam(learning_rate=global_learning_rate))\n",
    "    return model\n",
    "\n",
    "def run_experiment(model):\n",
    "    with tf.device(\"GPU\"):\n",
    "        history = model.fit(X_train,y_train,epochs=global_epochs,validation_data=(X_real,y_real),shuffle=False,verbose=0,\n",
    "                            batch_size=global_batch_size)\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Experiment q1 ===\n",
      "constant initialization 1 conv layer, 3 FC Dense of 32 Height\n",
      "Model: \"FC_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 192, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 127, 95, 32)       896       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 127, 95, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 47, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 94752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                3032096   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,035,368\n",
      "Trainable params: 3,035,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_83624/1383200925.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m \u001B[0mE\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"experiment_desc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_experiment_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mE\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"num_conv\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mE\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"initialization\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrun_experiment\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m     \u001B[0mdisplay_history\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mE\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"experiment_desc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_83624/1328285173.py\u001B[0m in \u001B[0;36mrun_experiment\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mrun_experiment\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"GPU\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m         history = model.fit(X_train,y_train,epochs=global_epochs,validation_data=(X_real,y_real),shuffle=False,verbose=0,\n\u001B[0m\u001B[0;32m     32\u001B[0m                             batch_size=global_batch_size)\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\lambda\\labs\\ds-test-2\\venv2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\lambda\\labs\\ds-test-2\\venv2\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1225\u001B[0m         \u001B[0mlogs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msync_to_numpy_or_python_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1226\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlogs\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1227\u001B[1;33m           raise ValueError('Unexpected result of `train_function` '\n\u001B[0m\u001B[0;32m   1228\u001B[0m                            \u001B[1;34m'(Empty logs). Please use '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1229\u001B[0m                            \u001B[1;34m'`Model.compile(..., run_eagerly=True)`, or '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "results={}\n",
    "for E in experiments:\n",
    "    print(\"\\n\")\n",
    "    print( f'=== Experiment {E[\"experiment_label\"]} ===')\n",
    "    print( E[\"experiment_desc\"])\n",
    "    model = create_experiment_model(E[\"num_conv\"],E[\"initialization\"])\n",
    "    history = run_experiment(model)\n",
    "    display_history(history,E[\"experiment_desc\"])\n",
    "\n",
    "    results[E[\"experiment_label\"]]={\n",
    "    \"min_val_mae\":np.array(history.history[\"val_loss\"]).min()\n",
    "    }\n",
    "print (f'number of seconds to run all experiments: {time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}